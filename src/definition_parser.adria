/*
 * Adria transcompiler
 *
 * Copyright (C) 2013 Dennis Möhlmann <mail@dennismoehlmann.de>
 * Licensed under the MIT license.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of
 * this software and associated documentation files (the "Software"), to deal in
 * the Software without restriction, including without limitation the rights to
 * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
 * the Software, and to permit persons to whom the Software is furnished to do so,
 * subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
 * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
 * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
 * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
var util = require('./util');
var Parser = require('./parser');
var Tokenizer = require('./tokenizer');
var Path = require('./definition_parser/path');

/**
 * Parser subclass hardwired with the required node tree to process the syntax of .sdt-files.
 * Provides trainOther() method to train another parser according to input .sdt-file using
 * the other parser's createNode and integrateNodePair methods
 */
module DefinitionParser = proto (Parser) {

    constructor: function() {

        Parser->constructor();

        this.tokenizer = new Tokenizer([
            Tokenizer.prefab.delimited(null, '/*', '*/'),
            Tokenizer.prefab.regex(null, /^\/\/.*/),
            Tokenizer.prefab.breaker(),
            Tokenizer.prefab.regex('WORD', /^[a-z_]+/i),
            Tokenizer.prefab.set('DELIM', [ '->', '.', ':', '[', ']', '{', '}', '?' ]),
            Tokenizer.prefab.regex('STRING', /^(["'])(?:(?=(\\?))\2[\s\S])*?\1/),
            Tokenizer.prefab.number('NUMERIC'),
        ]);

        // create a definition for the parser definition language

        this.trainSelf();

        // during processing lists (blocks) of node pairs (paths) are required

        this.pathBlocks = { };

        // a temporary used to analyze the current path ( a -> b )

        this.currentPath = new Path();
    },

    /**
     * callback called by Parser.parse() for all capturepoints found in a valid path
     *
     * @param string name capture name
     * @param string value captured value
     */
    capture: function(name, value) {

        var currentPath = this.currentPath;

        // block starting subdefinition

        if (name == 'block_name') {

            this.block_name = value;
            this.pathBlocks[this.block_name] = [ ];
            return;
        }

        // construct path pairs from complete paths (i.e. a->b->c becomes a->b, b->c) [from previous capture]

        if ((name == 'path' || name == 'source_name' || name == 'block_done') && currentPath.source.name != '' && currentPath.target.name != '') {

            // append new path to current block, then reset it (move target to source, clear target)

            this.pathBlocks[this.block_name].push(currentPath.clone());
            currentPath.reset();
        }

        // process current source/target. make sure the capture/label is reset when encountering a 'name'

        if (name == 'source_name') {

            currentPath.source.name       = value;
            currentPath.source.capture    = '';
            currentPath.source.label      = '';
            currentPath.source.condition  = '';

        } else if (name == 'target_name') {

            currentPath.target.name       = value;
            currentPath.target.capture    = '';
            currentPath.target.label      = '';
            currentPath.target.condition  = '';

        } else if (name == 'source_capture') {

            currentPath.source.capture    = value;

        } else if (name == 'target_capture') {

            currentPath.target.capture    = value;

        } else if (name == 'source_label') {

            currentPath.source.label      = value;

        } else if (name == 'target_label') {

            currentPath.target.label      = value;

        } else if (name == 'source_condition') {

            currentPath.source.condition  = value.slice(1, -1);

        } else if (name == 'target_condition') {

            currentPath.target.condition  = value.slice(1, -1);
        }
    },

    /**
     * parse file and use callback on captures
     */
    parse: function(source) {

        // call parent

        var results = Parser.prototype.parse.call(this, source);

        for (var id, result in results) {

            if (result.node.capture != '') {
                this.capture(result.node.capture, result.token.data);
            }
        }

        return results;
    },

    /**
     * process loaded .sdt using node_creator and node_pair_integrator callbacks from the target parser
     * effectively, this trains the target parser with a language definition
     */
    trainOther: function(parser) {

        var parts = [ 'source', 'target' ];

        // for each path group generated by the capture callback

        for (var block_name, block_paths in this.pathBlocks) {

            var node_map    = { };
            var node_pair   = [ ];

            // for each path (in each group)

            for (var id, path in block_paths) {

                // try to insert both source and target node

                for (var i, part in parts) {

                    var hash = path[part].name + ':' + path[part].capture + ':' + path[part].label;

                    // only insert if node not already known

                    node_pair[i] = node_map[hash];

                    if (node_pair[i] === undefined) {

                        // use userdefined mapping to create the node

                        var node = parser.createNode(path[part].name, path[part].capture, path[part].label, path[part].condition);

                        // remember node as known and insert it into the pair

                        node_map[hash] = node;
                        node_pair[i] = node;
                    }
                }

                // user defined node-integrator

                parser.integrateNodePair(node_pair, block_name);
            }
        }
    },

    /**
     * prepare definition of this parser for .sdt-file parsing
     */
    trainSelf: function() {

        var Type = this.tokenizer.Type;
        var block_root = new Parser.Definition.Node();
        this.definition.createBlock(null, block_root);

        // entry point is an identifier

        var blockname = block_root.createAndAdd(Type.WORD, /[\S\s]+/, 'block_name');
        var body = blockname.createAndAdd(Type.DELIM, '{', '', '{');

        // inside the body, an identifier 'source_name' is expected first (with optional secondary identifier
        // 'source_capture' and optional 'source_label')

        var node1a = body.createAndAdd(Type.WORD | Type.STRING, /[\S\s]+/, 'source_name');
        var node1b = node1a.createAndAdd(Type.DELIM, ':', '', ':');
        var node1c = node1b.createAndAdd(Type.WORD, /[\S\s]+/, 'source_capture');
        var node1d = node1c.createAndAdd(Type.DELIM, '[', '', '[');
        var node1e = node1d.createAndAdd(Type.WORD, /[\S\s]+/, 'source_label');
        var node1f = node1e.createAndAdd(Type.DELIM, ']', '', ']');
        var node1g = node1f.createAndAdd(Type.DELIM, '?', '', '?');
        var node1h = node1g.createAndAdd(Type.STRING, /[\S\s]+/, 'source_condition');
        node1a.add(node1d); // name[label]
        node1a.add(node1g); // name?condition
        node1c.add(node1g); // name[label]?condition

        // the connector symbol '->', attach to source_name, source_capture, source_label and source_condition

        var path1a = node1a.createAndAdd(Type.DELIM, '->', 'path', '->');
        node1h.add(path1a);
        node1f.add(path1a);
        node1c.add(path1a);

        // at least one path to another identifier has to be defined

        var node2a = path1a.createAndAdd(Type.WORD | Type.STRING, /[\S\s]+/, 'target_name');
        var node2b = node2a.createAndAdd(Type.DELIM, ':', '', ':');
        var node2c = node2b.createAndAdd(Type.WORD, /[\S\s]+/, 'target_capture');
        var node2d = node2c.createAndAdd(Type.DELIM, '[', '', '[');
        var node2e = node2d.createAndAdd(Type.WORD, /[\S\s]+/, 'target_label');
        var node2f = node2e.createAndAdd(Type.DELIM, ']', '', ']');
        var node2g = node2f.createAndAdd(Type.DELIM, '?', '', '?');
        var node2h = node2g.createAndAdd(Type.STRING, /[\S\s]+/, 'target_condition');
        node2a.add(node2d); // name[label]
        node2a.add(node2g); // name?condition
        node2c.add(node2g); // name[label]?condition

        // followed by the continuation of this path (capture moves last target to source)

        node2h.add(path1a);
        node2f.add(path1a);
        node2c.add(path1a);
        node2a.add(path1a);

        // ... or another identifier to start a new path ...

        node2h.add(node1a);
        node2f.add(node1a);
        node2c.add(node1a);
        node2a.add(node1a);

        // ... or the end of this body

        var bodyend = node2c.createAndAdd(Type.DELIM, '}', 'block_done', '}');
        node2a.add(bodyend);
        node2f.add(bodyend);
        node2h.add(bodyend);

        // or another block

        bodyend.add(blockname);

        // followed by the end of the document (only the nodetype is considered, set match to dummy)

        var exit = bodyend.createAndAdd(Type.WORD, 'exit');
        exit.type = Parser.Definition.Node.Type.RETURN;
    },
};
