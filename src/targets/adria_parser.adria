/*
 * Adria transcompiler
 *
 * Copyright (C) 2014 Dennis MÃ¶hlmann <mail@dennismoehlmann.de>
 * Licensed under the MIT license.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of
 * this software and associated documentation files (the "Software"), to deal in
 * the Software without restriction, including without limitation the rights to
 * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
 * the Software, and to permit persons to whom the Software is furnished to do so,
 * subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
 * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
 * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
 * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
var fs = require('fs');
var util = require('../util');
var Set = require('astd/set');
var LanguageParser = require('../language_parser');
var Tokenizer = require('../tokenizer');
var definition = require('./adria_definition');

/**
 * LanguageParser subclass defining additional Adria specific .sdt-file
 * entities and setting up blockname to class mappings.
 */
module AdriaParser = proto(LanguageParser) {

    moduleName  : '',
    indent      : 0,
    resultData  : null,

    constructor: func(transform) {

        LanguageParser->constructor(transform);

        this.resultData = {
            globals     : new Set(),
            requires    : new Set(),
            resources   : new Set(),
            isInterface : false,
        };
    },

    /**
     * returns new instance suitable for parsing
     */
    clone: func() {

        var parser = parent->clone();

        parser.resultData = {
            globals     : new Set(),
            requires    : new Set(),
            resources   : new Set(),
            isInterface : false,
        };

        return parser;
    },

    /**
     * preprocesses raw input string, replaces commandline defines {{DEFINE}}
     *
     * @param string data
     * @return string replaced data
     */
    preprocessRaw: func(data) {

        data = parent->preprocessRaw(data);

        var defines = this.transform.options.defines;

        return data.replace(/\{\{([a-zA-Z][a-zA-Z_0-9]*)\}\}/g, func(matches, key) {
            return (defines[key] === undefined ? '' : defines[key]);
        });
    },

    /**
     * initialize a tokenizer, load definition files into a trainer and call parent's trainself, which
     * will use the trainer to genererate the definition for this parser
     */
    trainSelf: func() {

        var keywords = new Set([
            'var', 'global',
            'if', 'else', 'for', 'in', 'do', 'while', 'switch', 'case', 'break', 'continue', 'return',
            'throw', 'try', 'catch', 'finally',
            'yield', 'await',
            'parent', 'self',
            'func', 'proto', 'prop', 'storage', //!todo TBD 'scope',
            'require', 'resource', 'module', 'export', 'interface',
            'delete', 'new', 'instanceof', 'typeof',
            'assert',
        ]);

        var matchKeywords = func(match) {

            if (keywords.has(match.data)) {
                match.name = 'KEYWORD';
            }
            return match;
        };

        this.tokenizer = new Tokenizer([
            Tokenizer.prefab.delimited(null, '/*', '*/'),
            Tokenizer.prefab.regex(null, /^\/\/.*/),
            Tokenizer.prefab.breaker(),
            Tokenizer.prefab.regex('REGEXP', /^\/(?:(?=(\\?))\1.)*?\/[a-z]*/, /^(\(|=|==|===|\+|!=|!==|,|;|\:)$/),
            Tokenizer.prefab.set('DELIM', [ ';', '...', '.', ',', '(', ')', '[', ']', '{', '}', '!==', '!=', '!', '++', '--', '#' ]),
            Tokenizer.prefab.group('DELIM', [ '=', '&', '|', '<', '>', ':', '?', '+', '-', '*', '/', '%' ]),
            Tokenizer.prefab.regex('IDENT', /^[a-zA-Z_\$][a-zA-Z0-9_\$]*/, null, matchKeywords),
            Tokenizer.prefab.number('NUMERIC'),
            Tokenizer.prefab.regex('STRING', /^(["'])(?:(?=(\\?))\2[\s\S])*?\1/),
        ], [ 'KEYWORD' ]);

        log('AdriaParser', 'trainer processing adria .sdt-files', 2);
        this.setDefinition(resource('../../definition/adria/control.sdt'), 'control');
        this.setDefinition(resource('../../definition/adria/expression.sdt'), 'expression');
        this.setDefinition(resource('../../definition/adria/literal.sdt'), 'literal');
        this.setDefinition(resource('../../definition/adria/proto.sdt'), 'proto');
        this.setDefinition(resource('../../definition/adria/root.sdt'), 'root');
        this.setDefinition(resource('../../definition/adria/statement.sdt'), 'statement');

        log('AdriaParser', 'being trained', -2);
        LanguageParser->trainSelf();
        log('AdriaParser', 'done');
    },

    /**
     * maps capture_names to subclasses of CaptureNode
     *
     * @param string captureName node capture name (unused at the moment)
     * @param string blockName name of the block containing the node (mapped to classname)
     */
    mapType: func(captureName, blockName) {

        var typeName = blockName.snakeToCamel(true);

        if (typeof definition[typeName] === 'function') {
            return definition[typeName];
        }

        return definition.Node;
    },

    /**
     * add definition file support for ident, name and regex tag
     *
     * @return Parser.Definition.Node
     */
    createNode: func(name, capture, label, condition) {

        var node = LanguageParser->createNode(name, capture, label, condition);

        if (name === 'ident') {

            node.match          = '';
            node.type           = 0;
            node.tokenType      = this.tokenizer.Type.IDENT;
            node.description    = 'identifier';

        } else if (name === 'name') {

            node.match          = '';
            node.type           = 0;
            node.tokenType      = this.tokenizer.Type.IDENT | this.tokenizer.Type.KEYWORD;
            node.description    = 'name';

        } else if (name === 'regexp') {

            node.match          = '';
            node.type           = 0;
            node.tokenType      = this.tokenizer.Type.REGEXP;
            node.description    = 'regexp';
        }

        return node;
    },

    /**
     * change loadSourceFromCache behaviour to also load the original source,
     * if source-mapping is enabled
     *
     * @see LanguageParser::loadSourceFromCache
     */
    loadSourceFromCache: func(filename, cacheModifier = null) {

        LanguageParser->loadSourceFromCache(filename, cacheModifier);

        if (this.cacheData !== null && this.transform.options['map']) {
            this.sourceCode = fs.readFileSync(filename, 'UTF-8').replace('\r\n', '\n');
        }
    },
};
